table(nrc$sentiment)
g <- gutenberg_works()
library(gutenbergr)
library(dplyr)
library(magrittr)
library(tidytext)
library(tidyr)
library(ggplot2)
g <- gutenberg_works()
id <- c(83, 103, 164, 1268)
verne <- gutenberg_download(id)
books <- g[g$gutenberg_id %in% id, c("gutenberg_id","title")]
verne %<>% left_join(books) %>%
mutate(gutenberg_id = NULL)
verne_books <- verne %>%
group_by(title) %>%
mutate(linenumber = row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
pos_neg <- verne_books %>%
inner_join(nrc) %>%
filter(sentiment %in% c("positive", "negative")) %>%
group_by(sentiment) %>%
count(word, sort = T) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word = reorder(word, n))
ggplot(pos_neg) + geom_col(aes(word, n, fill = sentiment)) +
coord_flip() +
facet_wrap( ~ sentiment, scales = "free")
nrc_class <- verne_books %>%
filter(title == books[["title"]][2]) %>%
inner_join(nrc) %>%
filter(!(sentiment %in% c("positive", "negative"))) %>%
group_by(sentiment) %>%
count(word, sort = T) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word = reorder(word, n))
ggplot(nrc_class) + geom_col(aes(word, n, fill = sentiment), show.legend = FALSE) +
coord_flip() +
facet_wrap(~sentiment, nrow = 3, scales = "free")
verne_senti_bing <- verne_books %>%
inner_join(get_sentiments("bing")) %>%
count(title, index = linenumber %/% 80, sentiment)
verne_senti_bing
verne_senti_bing %<>%
spread(sentiment, n, fill = 0)
verne_senti_bing
ggplot(verne_senti_bing, aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ title, ncol = 2, scales = "free_x")
verne_senti_bing %<>%
mutate(sentiment = positive - negative)
ggplot(verne_senti_bing, aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ title, ncol = 2, scales = "free_x")
emo <- as_tibble(read.csv("http://www.fizyka.pw.edu.pl/~julas/TEXT/lab/Ratings_Warriner_et_al.csv", stringsAsFactors = F))
emo
emo <- as_tibble(read.csv("http://www.fizyka.pw.edu.pl/~julas/TEXT/lab/Ratings_Warriner_et_al.csv", stringsAsFactors = F))
emo <- as_tibble(read.csv("http://www.fizyka.pw.edu.pl/~julas/TEXT/lab/Ratings_Warriner_et_al.csv", stringsAsFactors = F))
library(reshape2)
install.packages("reshape2")
library(reshape2)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
verne_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "darkgreen"),
max.words = 100)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
View(bigrams_nouns)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
View(bigrams)
View(top_nouns)
top_bigrams <- bigrams %>% left_join(top_nouns, by = c("word2" = "word2"))
View(top_bigrams)
top_bigrams <- bigrams %>% right_join(top_nouns, by = c("word2" = "word2"))
bigrams2 <- bigrams %>%
left_join(parts_of_speech, by = c("word1" = "word"))
View(bigrams2)
?left_join
bigrams2 <- bigrams %>%
left_join(parts_of_speech, by = c("word1" = "word"), suffix = c("1", "2"))
View(bigrams2)
bigrams2 <- bigrams %>%
left_join(parts_of_speech, by = c("word1" = "word"), suffix = c("2", "1"))
bigrams <- verne %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigrams <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams <- bigrams %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
nrc <- get_sentiments("nrc")
bigrams <- bigrams %>%
left_join(parts_of_speech, by = c("word2" = "word")) %>%
filter(pos == "Noun") %>%
left_join(parts_of_speech, by = c("word1" = "word"), suffix = c("2", "1"))
View(bigrams)
top_nouns <- bigrams %>% count(word2) %>% top_n(3)
print(paste("Most used nouns: ", top_nouns$word2[1],", ", top_nouns$word2[2],", ", top_nouns$word2[3]))
top_bigrams <- bigrams %>% right_join(top_nouns, by = c("word2" = "word2"))
top_bigrams %>%
count(pos1, sort = T)
pos <- top_bigrams %>%
count(pos1, sort = T) %>%
mutate(nn = n / sum(n))
pos
ggplot(pos) +
geom_bar(aes(x = reorder(pos, -nn), nn, fill = reorder(pos, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
ggplot(pos) +
geom_bar(aes(x = reorder(pos, -nn), nn, fill = reorder(pos, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
View(bigrams2)
pos <- top_bigrams[top_bigrams$word1 == top_nouns$word2[1]] %>%
count(pos1, sort = T) %>%
mutate(nn = n / sum(n))
df2 <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n(),.groups = 'drop')
View(df2)
View(top_nouns)
top_nouns <- bigrams %>% count(word2) %>% top_n(3) %>% sort()
top_nouns <- bigrams %>% count(word2) %>% top_n(3) %>% sort()
View(top_nouns)
top_nouns <- top_nouns[order(top_nouns$n),]
View(top_nouns)
top_nouns <- top_nouns[order(-top_nouns$n),]
View(top_nouns)
print(paste("Most used nouns: ", top_nouns$word2[1],", ", top_nouns$word2[2],", ", top_nouns$word2[3]))
View(df2)
print(paste("Most used nouns:", top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]))
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n()) %>%
mutate(nn = n / sum(n))
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n())
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(n=n())
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(n=n())
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n())
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n(),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n(),.groups = 'drop')
View(top_bigrams)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos <- pos %>% group_by(word2) %>%
summarise(pos_total=n(),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos %>% group_by(word2) %>%
count(pos_count, sort = T)
pos %>% group_by(word2)
pos %>% group_by(word2) %>%
count(pos_count, sort = T)
?summarise
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(), total_count= sum(pos1),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(), total_count= sum(pos_count),.groups = 'drop')
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(), total_count= sum(n()),.groups = 'drop')
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
count(pos1, sort = T)
View(pos2)
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=n(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos1),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos1),.groups = 'drop')
View(pos)
pos2 <- pos %>% group_by(word2, pos1) %>%
summarise(total_count=sum(),.groups = 'drop')
View(pos2)
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos_count),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop') %>% left_join(top_bigrams, by = c("word2" = "word2"))
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop') %>% left_join(top_bigrams[["word2", "n"]], by = c("word2" = "word2"))
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop') %>% left_join(top_bigrams[["word2", "n"],], by = c("word2" = "word2"))
top_bigrams[["word2", "n"],:]
top_bigrams[["word2", "n"],]
top_bigrams[c("word2", "n"),]
select(top_bigrams, c("word2", "n"))
select(top_bigrams, c("word2", "n")) %>% group_by(word2)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos_count),.groups = 'drop')
pos3 <- pos %>% left_join(pos2, by = c("word2" = "word2"))
View(pos3)
pos3 <- pos %>% left_join(pos2, by = c("word2" = "word2")) %>%
mutate(nn = pos_count / total_count)
pos3 <- pos3[order(-n, nn),]
pos3 <- pos3[order(-total_count, nn),]
pos3 <- pos3[order(-total_count, nn),]
pos3 <- pos3[order(-total_count, -nn),]
pos3 <- pos3[order(total_count, -nn),]
pos3 <- pos3[order(-pos3$total_count, -pos3$nn),]
pos <- pos %>% left_join(pos2, by = c("word2" = "word2")) %>%
mutate(nn = pos_count / total_count)
pos <- pos3[order(-pos3$total_count, -pos3$nn),]
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS") + facet_wrap(~word2)
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS") + facet_wrap(~word2) + coord_flip()
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE) %>%
acast(word1 ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "darkgreen"), max.words = 100)
top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE) %>%
acast(word1 ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "darkgreen"), max.words = 100)
text(x=0, y=0, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
text(x=-1, y=0, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
text(x=-1, y=0, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
text(x=0, y=-0.5, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
top_bigrams_sentiments <- top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE) %>%
top_bigrams_sentiments <- top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE)
top_bigrams_sentiments <- top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE)
View(top_bigrams_sentiments)
top_bigrams_sentiments <- top_bigrams %>%
left_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE)
View(top_bigrams_sentiments)
top_bigrams_sentiments <- top_bigrams %>%
left_join(get_sentiments("bing"), by = c("word1" = "word"))
View(top_bigrams_sentiments)
View(top_bigrams_sentiments)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad6/zad6.R", echo=TRUE)
data.bbc.equal %>%
group_by(emo) %>%
summarise(n = n())
dim(tdm); length(class)
tmp <- slim.tdm.matrix(tdm,data.bbc.equal, 5, 1)
tdm <- tmp[[1]]
class <- tmp[[2]]
dim(tdm); length(class)
model.equal <- make.svm.model(tdm, class)
tdm <- make.tdm.matrix(data.bbc.equal)
tmp <- slim.tdm.matrix(tdm,data.bbc.equal, 5, 1)
tdm <- tmp[[1]]
class <- tmp[[2]]
dim(tdm); length(class)
model.equal <- make.svm.model(tdm, class)
confusionMatrix(model.random)
confusionMatrix(model.equal)
res <- resamples(list(Random = model.random, Equal = model.equal))
bwplot(res)
tdm <- make.tdm.matrix(data.bbc.equal)
tmp <- slim.tdm.matrix(tdm,data.bbc.equal, 6, 1)
tdm <- tmp[[1]]
class <- tmp[[2]]
dim(tdm); length(class)
model.equal <- make.svm.model(tdm, class)
confusionMatrix(model.equal)
res <- resamples(list(Random = model.random, Equal = model.equal))
bwplot(res)
tdm <- make.tdm.matrix(data.bbc.equal)
tmp <- slim.tdm.matrix(tdm,data.bbc.equal, 4, 1)
tdm <- tmp[[1]]
class <- tmp[[2]]
dim(tdm); length(class)
model.equal <- make.svm.model(tdm, class)
res <- resamples(list(Random = model.random, Equal = model.equal))
bwplot(res)
library(dplyr)
library(tidytext)
library(tm)
library(lsa)
library(gutenbergr)
library(topicmodels)
library(ggplot2)
rm(list = ls())
g <- gutenberg_works()
verne_en <- gutenberg_works(languages = "en") %>%
filter(author == "Verne, Jules")
austen_en <- gutenberg_works(languages = "en") %>%
filter(author == "Austen, Jane")
verne_en_ids <- c(83, 103, 3526)
verne_en_books <- verne_en[verne_en$gutenberg_id %in% verne_en_ids,c("gutenberg_id","title", "author")]
austen_en_ids <- c(105, 121, 141)
austen_en_books <- austen_en[austen_en$gutenberg_id %in% austen_en_ids,c("gutenberg_id","title", "author")]
v <- gutenberg_download(c(verne_en_ids,austen_en_ids))
v <- left_join(v, rbind(verne_en_books, austen_en_books))
df <- v %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " "))
removeSpecialChars <- function(x) gsub("[^0-9A-Za-z///' ]"," ",x)
docs_ids <- seq(1:6)
df$doc_id <- docs_ids
titles <- df$title
corpus_verne <- VCorpus(DataframeSource(as.data.frame(df[df$author == "Verne, Jules",])))
corpus_verne <- corpus_verne %>% tm_map(removeWords, stopwords("english")) %>%
tm_map(content_transformer(removeSpecialChars)) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
View(corpus_verne)
doc_verne <- TermDocumentMatrix(corpus_verne)
View(doc_verne)
txt <- c("asda224", "24asaf")
removeSpecialChars(txt)
removeSpecialChars <- function(x) gsub("[0-9A-Za-z///' ]"," ",x)
removeSpecialChars <- function(x) gsub("[0-9A-Za-z///' ]"," ",x)
removeSpecialChars(txt)
removeNumbers(txt)
removeNumbers(df$text)
View(df)
df$text<- removeNumbers(df$text)
titles <- df$title
View(df)
corpus_verne <- VCorpus(DataframeSource(as.data.frame(df[df$author == "Verne, Jules",])))
corpus_verne <- corpus_verne %>% tm_map(removeWords, stopwords("english")) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removeSpecialChars)) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
doc_verne <- TermDocumentMatrix(corpus_verne)
ap_lda <- LDA(doc_verne, k = 2, control = list(seed = 1234))
ap_topics <- tidy(ap_lda, matrix = "beta")
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") + scale_x_reordered() + coord_flip()
View(doc_verne)
doc_verne[["dimnames"]][["Terms"]]
df$text
corpus_verne <- VCorpus(DataframeSource(as.data.frame(df[df$author == "Verne, Jules",])))
corpus_verne <- corpus_verne %>% tm_map(removeWords, stopwords("english")) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removeSpecialChars)) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
doc_verne <- TermDocumentMatrix(corpus_verne)
View(doc_verne)
doc_verne[["dimnames"]][["Terms"]]
View(df)
doc_verne
df <- v %>%
group_by(title, author) %>%
summarise(text = paste(text, collapse = " "))
df$doc_id <- docs_ids
corpus_verne <- VCorpus(DataframeSource(as.data.frame(df[df$author == "Verne, Jules",])))
corpus_verne <- corpus_verne %>% tm_map(removeWords, stopwords("english")) %>%
tm_map(removePunctuation) %>%
tm_map(content_transformer(tolower)) %>%
tm_map(content_transformer(removeSpecialChars)) %>%
tm_map(stripWhitespace) %>%
tm_map(stemDocument)
doc_verne <- TermDocumentMatrix(corpus_verne)
doc_verne
View(doc_verne)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad8/zad8.R", echo=TRUE)
setwd("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad8")
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad8/zad8.R", echo=TRUE)
diff(df3$Time)
difftime(df3$Time)
time.diff <- c(0)
df3$Time
df3$Time[1]
difftime(df3$Time[1], df3$Time[2])
View(df3)
difftime(df3$Time[3], df3$Time[2])
difftime(df3$Time[3], df3$Time[2], units = "secs")
difftime(df3$Time[1], df3$Time[2], units = "secs")
for (i in 1:29){
time.diff <- append(time.diff,difftime(df3$Time[i-1], df3$Time[i], units = "secs"))
}
df3$Time.diff <- time.diff
for (i in 2:30){
time.diff <- append(time.diff,difftime(df3$Time[i-1], df3$Time[i], units = "secs"))
}
time.diff <- c(0)
for (i in 2:30){
time.diff <- append(time.diff,difftime(df3$Time[i-1], df3$Time[i], units = "secs"))
}
df3$Time.diff <- time.diff
View(df3)
time.diff <- c(0)
for (i in 2:30){
time.diff <- append(time.diff,difftime(df3$Time[i], df3$Time[i-1], units = "secs"))
}
df3$Time.diff <- time.diff
df3$Time.diff <- time.diff * 60 * 60
df3$Time.diff <- time.diff / (60 * 60)
velocity <- c(0)
df3$Time.diff[-1]
df3$Time.diff[-2]
df3$Time.diff[]
df3$Time.diff[-1]
df3$distances[-1]/df3$Time.diff[-1]
velocity <- append(velocity, df3$distances[-1]/df3$Time.diff[-1])
df3$Velocity <- Velocity
velocity <- append(velocity, df3$distances[-1]/df3$Time.diff[-1])
df3$Velocity <- Velocity
velocity <- c(0)
velocity <- append(velocity, df3$distances[-1]/df3$Time.diff[-1])
df3$Velocity <- Velocity
df3$Velocity <- velocity
View(df3)
df3$Predkosc <- velocity
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point()
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point() + stat_smooth(method = "lm",formula = y ~ poly(x, 4))
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point() + stat_smooth(method = "lm",formula = y ~ poly(x, 4)) +
labs(x = "Czas [min]", y = "Prędkość [km/h]")
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point() + stat_smooth(method = "lm",formula = y ~ poly(x, 4)) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point() + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point(colour = "red", size = 3) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line( color="grey") +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line(color="grey", linetype = "dashed") +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line(color="grey", linetype = "dotted") +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line(color="grey", linetype = "dotted", size=2) +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line(color="grey", linetype = "dotted", size=1) +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line(color="black", linetype = "dotted", size=1) +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
ggp <- ggplot(df3, aes(Czas, Predkosc)) + geom_line(color="black", linetype = "dotted", size=0.5) +
geom_point(colour = "red", size = 2) + stat_smooth(method = "lm",formula = y ~ poly(x, 4), se = FALSE) +
labs(x = "Czas [min]", y = "Prędkość [km/h]") + ylim(0, 40)
ggp
