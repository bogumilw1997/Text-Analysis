geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", 32, ", p:", cor.test(df$b_en, df$b_fr)$p.value))
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", 32, ", p:", cor.test(df$b_en, df$b_fr)$p.value))
plot(g1)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", 32, ", p:", round(cor.test(df$b_en, df$b_fr)$p.value)))
plot(g1)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", 32, ", p:", round(cor.test(df$b_en, df$b_fr)$p.value), 4))
plot(g1)
?round
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", 32, ", p:", round(cor.test(df$b_en, df$b_fr)$p.value), 6))
plot(g1)
cor.test(df$b_en, df$b_fr)$p.value
?cor.test
cor.test(df$b_en, df$b_fr)$statistic
cor.test(df$b_en, df$b_fr)$estimate
cor.test(df$b_en, df$b_fr)$estimate[1]
cor.test(df$b_en, df$b_fr)$estimate
round(cor.test(df$b_en, df$b_fr)$estimate)
round(cor.test(df$b_en, df$b_fr)$estimate, 2)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", round(cor.test(df$b_en, df$b_fr)$estimate, 2), ", p:", round(cor.test(df$b_en, df$b_fr)$p.value), 6))
plot(g1)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", round(cor.test(df$b_en, df$b_fr)$estimate, 2), ", p:", round(cor.test(df$b_en, df$b_fr)$p.value, 4)))
plot(g1)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", round(cor.test(df$b_en, df$b_fr)$estimate, 2), ", p:", round(cor.test(df$b_en, df$b_fr)$p.value, 3)))
plot(g1)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, corr:", round(cor.test(df$b_en, df$b_fr)$estimate, 2), ", p-value:", round(cor.test(df$b_en, df$b_fr)$p.value, 3)))
plot(g1)
g1 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) + ggtitle(paste("Non-shuffle, cor:", round(cor.test(df$b_en, df$b_fr)$estimate, 2), ", p-value:", round(cor.test(df$b_en, df$b_fr)$p.value, 3)))
plot(g1)
cor.test(df$b_en, df$b_fr)
View(verne_heaps)
sample(verne_heaps$word)
View(v)
v %>%
unnest_tokens(word, text)
v %>%
unnest_tokens(word, text)%>%
group_by(title)
v %>%
split(.$gutenberg_id) %>%
.[sample(names(.))] %>%
bind_rows
v1 <- v %>%
split(.$gutenberg_id) %>%
.[sample(names(.))] %>%
bind_rows
View(v1)
v1 <- v %>%
split(.$gutenberg_id) %>%
.[sample(word(.))] %>%
bind_rows
print(x)
for (x in verne_fr_ids) {
print(x)
}
v1 <- data.frame(v)
v1 <- v %>%
unnest_tokens(word, text)%>%
group_by(title)
v1[v1$gutenberg_id == id, "word"] = sample(v1$word)
v1[v1$gutenberg_id == 799, "word"]
sample(v1[v1$gutenberg_id == 799, "word"])
sample(v1[v1$gutenberg_id == 799, "word"])
sample(v1[v1$gutenberg_id == 799, "word"])
sample(v1[v1$gutenberg_id == 799]$word)
sample(v1[v1$gutenberg_id == 799, ]$word)
v1[v1$gutenberg_id == id, "word"] = sample(v1[v1$gutenberg_id == id, ]$word)
print(id)
for (id in verne_fr_ids) {
print(id)
}
for (id in verne_fr_ids) {
v1[v1$gutenberg_id == id, "word"] = sample(v1[v1$gutenberg_id == id, ]$word)
}
for (id in verne_en_ids) {
v1[v1$gutenberg_id == id, "word"] = sample(v1[v1$gutenberg_id == id, ]$word)
}
verne_heaps <- v1 %>%
mutate(M = row_number(), V = cumsum(!duplicated(word)))
View(verne_heaps)
verne_sum <- verne_heaps %>%
summarise(a = lm(log10(V) ~ log10(M))$coefficients[1], a_error = summary(lm(log10(V) ~ log10(M)))$coefficients[1,2],
b = lm(log10(V) ~ log10(M))$coefficients[2], b_error = summary(lm(log10(V) ~ log10(M)))$coefficients[2,2])
verne_sum <- left_join(verne_sum, rbind(verne_en_books, verne_fr_books))
b_en <- verne_sum[match(verne_en_ids, verne_sum$gutenberg_id),]$b
b_fr <- verne_sum[match(verne_fr_ids, verne_sum$gutenberg_id),]$b
b_en_error <- verne_sum[match(verne_en_ids, verne_sum$gutenberg_id),]$b_error
b_fr_error <- verne_sum[match(verne_fr_ids, verne_sum$gutenberg_id),]$b_error
df <- data.frame(b_en, b_en_error, b_fr, b_fr_error)
g2 <- ggplot(df, aes(x=b_en, y=b_fr)) +
geom_pointrange(aes(ymin=b_fr-b_fr_error, ymax=b_fr+b_fr_error,
xmin=b_en-b_en_error, xmax=b_en+b_en_error)) +
ggtitle(paste("Shuffle, cor:", round(cor.test(df$b_en, df$b_fr)$estimate, 2),
", p-value:", round(cor.test(df$b_en, df$b_fr)$p.value, 3)))
plot(g2)
g <- grid.arrange(g1,g2, ncol=2, nrow=1, left = "TF-IDF/TF", top = "cross/cosinus")
g <- grid.arrange(g1,g2, ncol=1, nrow=2, left = "TF-IDF/TF", top = "cross/cosinus")
g <- grid.arrange(g1,g2, ncol=1, nrow=2)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad3/zad3.R")
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad3/zad3.R")
nrc <- get_sentiments("nrc")
library(gutenbergr)
library(dplyr)
library(magrittr)
library(tidytext)
library(tidyr)
library(ggplot2)
nrc <- get_sentiments("nrc")
2
options(timeout=1000000)
nrc <- get_sentiments("nrc")
table(nrc$sentiment)
nrc <- get_sentiments("nrc")
table(nrc$sentiment)
nrc <- get_sentiments("nrc")
nrc <- get_sentiments("nrc")
library(remotes)
install.packages("remotes")
library(remotes)
install_github("EmilHvitfeldt/textdata")
install_github("juliasilge/tidytext")
nrc <- get_sentiments("nrc")
library(remotes)
install_github("juliasilge/tidytext")
nrc <- get_sentiments("nrc")
library(dplyr)
library(magrittr)
library(tidytext)
library(tidyr)
library(ggplot2)
nrc <- get_sentiments("nrc")
textdata::lexicon_nrc(delete = TRUE)
options(timeout=100000)
nrc <- get_sentiments("nrc")
table(nrc$sentiment)
g <- gutenberg_works()
library(gutenbergr)
library(dplyr)
library(magrittr)
library(tidytext)
library(tidyr)
library(ggplot2)
g <- gutenberg_works()
id <- c(83, 103, 164, 1268)
verne <- gutenberg_download(id)
books <- g[g$gutenberg_id %in% id, c("gutenberg_id","title")]
verne %<>% left_join(books) %>%
mutate(gutenberg_id = NULL)
verne_books <- verne %>%
group_by(title) %>%
mutate(linenumber = row_number()) %>%
ungroup() %>%
unnest_tokens(word, text)
pos_neg <- verne_books %>%
inner_join(nrc) %>%
filter(sentiment %in% c("positive", "negative")) %>%
group_by(sentiment) %>%
count(word, sort = T) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word = reorder(word, n))
ggplot(pos_neg) + geom_col(aes(word, n, fill = sentiment)) +
coord_flip() +
facet_wrap( ~ sentiment, scales = "free")
nrc_class <- verne_books %>%
filter(title == books[["title"]][2]) %>%
inner_join(nrc) %>%
filter(!(sentiment %in% c("positive", "negative"))) %>%
group_by(sentiment) %>%
count(word, sort = T) %>%
top_n(10, n) %>%
ungroup() %>%
mutate(word = reorder(word, n))
ggplot(nrc_class) + geom_col(aes(word, n, fill = sentiment), show.legend = FALSE) +
coord_flip() +
facet_wrap(~sentiment, nrow = 3, scales = "free")
verne_senti_bing <- verne_books %>%
inner_join(get_sentiments("bing")) %>%
count(title, index = linenumber %/% 80, sentiment)
verne_senti_bing
verne_senti_bing %<>%
spread(sentiment, n, fill = 0)
verne_senti_bing
ggplot(verne_senti_bing, aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ title, ncol = 2, scales = "free_x")
verne_senti_bing %<>%
mutate(sentiment = positive - negative)
ggplot(verne_senti_bing, aes(index, sentiment, fill = title)) +
geom_col(show.legend = FALSE) +
facet_wrap( ~ title, ncol = 2, scales = "free_x")
emo <- as_tibble(read.csv("http://www.fizyka.pw.edu.pl/~julas/TEXT/lab/Ratings_Warriner_et_al.csv", stringsAsFactors = F))
emo
emo <- as_tibble(read.csv("http://www.fizyka.pw.edu.pl/~julas/TEXT/lab/Ratings_Warriner_et_al.csv", stringsAsFactors = F))
emo <- as_tibble(read.csv("http://www.fizyka.pw.edu.pl/~julas/TEXT/lab/Ratings_Warriner_et_al.csv", stringsAsFactors = F))
library(reshape2)
install.packages("reshape2")
library(reshape2)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
verne_books %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
acast(word ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "darkgreen"),
max.words = 100)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
View(bigrams_nouns)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
View(bigrams)
View(top_nouns)
top_bigrams <- bigrams %>% left_join(top_nouns, by = c("word2" = "word2"))
View(top_bigrams)
top_bigrams <- bigrams %>% right_join(top_nouns, by = c("word2" = "word2"))
bigrams2 <- bigrams %>%
left_join(parts_of_speech, by = c("word1" = "word"))
View(bigrams2)
?left_join
bigrams2 <- bigrams %>%
left_join(parts_of_speech, by = c("word1" = "word"), suffix = c("1", "2"))
View(bigrams2)
bigrams2 <- bigrams %>%
left_join(parts_of_speech, by = c("word1" = "word"), suffix = c("2", "1"))
bigrams <- verne %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigrams <- bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ")
bigrams <- bigrams %>%
filter(!word1 %in% stop_words$word) %>%
filter(!word2 %in% stop_words$word)
nrc <- get_sentiments("nrc")
bigrams <- bigrams %>%
left_join(parts_of_speech, by = c("word2" = "word")) %>%
filter(pos == "Noun") %>%
left_join(parts_of_speech, by = c("word1" = "word"), suffix = c("2", "1"))
View(bigrams)
top_nouns <- bigrams %>% count(word2) %>% top_n(3)
print(paste("Most used nouns: ", top_nouns$word2[1],", ", top_nouns$word2[2],", ", top_nouns$word2[3]))
top_bigrams <- bigrams %>% right_join(top_nouns, by = c("word2" = "word2"))
top_bigrams %>%
count(pos1, sort = T)
pos <- top_bigrams %>%
count(pos1, sort = T) %>%
mutate(nn = n / sum(n))
pos
ggplot(pos) +
geom_bar(aes(x = reorder(pos, -nn), nn, fill = reorder(pos, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
ggplot(pos) +
geom_bar(aes(x = reorder(pos, -nn), nn, fill = reorder(pos, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
View(bigrams2)
pos <- top_bigrams[top_bigrams$word1 == top_nouns$word2[1]] %>%
count(pos1, sort = T) %>%
mutate(nn = n / sum(n))
df2 <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n(),.groups = 'drop')
View(df2)
View(top_nouns)
top_nouns <- bigrams %>% count(word2) %>% top_n(3) %>% sort()
top_nouns <- bigrams %>% count(word2) %>% top_n(3) %>% sort()
View(top_nouns)
top_nouns <- top_nouns[order(top_nouns$n),]
View(top_nouns)
top_nouns <- top_nouns[order(-top_nouns$n),]
View(top_nouns)
print(paste("Most used nouns: ", top_nouns$word2[1],", ", top_nouns$word2[2],", ", top_nouns$word2[3]))
View(df2)
print(paste("Most used nouns:", top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]))
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n()) %>%
mutate(nn = n / sum(n))
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n())
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(n=n())
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(n=n())
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n())
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n(),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(total_count=n(),.groups = 'drop')
View(top_bigrams)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos <- pos %>% group_by(word2) %>%
summarise(pos_total=n(),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos %>% group_by(word2) %>%
count(pos_count, sort = T)
pos %>% group_by(word2)
pos %>% group_by(word2) %>%
count(pos_count, sort = T)
?summarise
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(), total_count= sum(pos1),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(), total_count= sum(pos_count),.groups = 'drop')
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(), total_count= sum(n()),.groups = 'drop')
View(pos)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
count(pos1, sort = T)
View(pos2)
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=n(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos1),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos1),.groups = 'drop')
View(pos)
pos2 <- pos %>% group_by(word2, pos1) %>%
summarise(total_count=sum(),.groups = 'drop')
View(pos2)
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos_count),.groups = 'drop')
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop') %>% left_join(top_bigrams, by = c("word2" = "word2"))
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop') %>% left_join(top_bigrams[["word2", "n"]], by = c("word2" = "word2"))
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop') %>% left_join(top_bigrams[["word2", "n"],], by = c("word2" = "word2"))
top_bigrams[["word2", "n"],:]
top_bigrams[["word2", "n"],]
top_bigrams[c("word2", "n"),]
select(top_bigrams, c("word2", "n"))
select(top_bigrams, c("word2", "n")) %>% group_by(word2)
pos <- top_bigrams %>% group_by(word2,pos1) %>%
summarise(pos_count=n(),.groups = 'drop')
pos2 <- pos %>% group_by(word2) %>%
summarise(total_count=sum(pos_count),.groups = 'drop')
pos3 <- pos %>% left_join(pos2, by = c("word2" = "word2"))
View(pos3)
pos3 <- pos %>% left_join(pos2, by = c("word2" = "word2")) %>%
mutate(nn = pos_count / total_count)
pos3 <- pos3[order(-n, nn),]
pos3 <- pos3[order(-total_count, nn),]
pos3 <- pos3[order(-total_count, nn),]
pos3 <- pos3[order(-total_count, -nn),]
pos3 <- pos3[order(total_count, -nn),]
pos3 <- pos3[order(-pos3$total_count, -pos3$nn),]
pos <- pos %>% left_join(pos2, by = c("word2" = "word2")) %>%
mutate(nn = pos_count / total_count)
pos <- pos3[order(-pos3$total_count, -pos3$nn),]
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS")
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS") + facet_wrap(~word2)
ggplot(pos) +
geom_bar(aes(x = reorder(pos1, -nn), nn, fill = reorder(pos1, nn)), stat="identity") +
coord_flip() + theme(legend.position = "none") +
labs(y = "fraction", x = "POS") + facet_wrap(~word2) + coord_flip()
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
source("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5/zad5.R", echo=TRUE)
top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE) %>%
acast(word1 ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "darkgreen"), max.words = 100)
top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE) %>%
acast(word1 ~ sentiment, value.var = "n", fill = 0) %>%
comparison.cloud(colors = c("red", "darkgreen"), max.words = 100)
text(x=0, y=0, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
text(x=-1, y=0, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
text(x=-1, y=0, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
text(x=0, y=-0.5, paste(top_nouns$word2[1],",", top_nouns$word2[2],",", top_nouns$word2[3]), cex = 0.5)
top_bigrams_sentiments <- top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE) %>%
top_bigrams_sentiments <- top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE)
top_bigrams_sentiments <- top_bigrams %>%
inner_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE)
View(top_bigrams_sentiments)
top_bigrams_sentiments <- top_bigrams %>%
left_join(get_sentiments("bing"), by = c("word1" = "word")) %>%
count(word1, sentiment, sort = TRUE)
View(top_bigrams_sentiments)
top_bigrams_sentiments <- top_bigrams %>%
left_join(get_sentiments("bing"), by = c("word1" = "word"))
View(top_bigrams_sentiments)
View(top_bigrams_sentiments)
setwd("C:/Users/bogum/Desktop/mgr_studia/semestr3/Text/zad5")
library(dplyr)
library(tidytext)
library(magrittr)
data.bbc <- as_tibble(read.table("https://jsienkiewicz.pl/TEXT/lab/data_bbc.csv", stringsAsFactors = F))
data.bbc
data.bbc %>%
group_by(emo) %>%
summarise(n = n())
data.bbc %<>%
arrange(desc(emo)) %>%
slice(-c(501:(n()-498)))
data.bbc$text <- sapply(data.bbc$text, enc2utf8)
data.bbc$emo <- as.factor(data.bbc$emo)
data.bbc <- data.bbc[sample(1:nrow(data.bbc)),]
data.bbc$doc_id <- 1:nrow(data.bbc)
library(tm)
View(data.bbc)
source <- DataframeSource(as.data.frame(data.bbc))
corpus <- VCorpus(source)
corpus %<>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace) %>%
tm_map(removeNumbers)
tdm <- DocumentTermMatrix(corpus)
tdm
tdm.count <- apply(tdm, 2, sum)
h <- hist(tdm.count, breaks = max(tdm.count), plot = F)
plot(h$mids, h$counts, log="xy", pch = 19, xlab = "ile razy słowo powtórzyło się w dokumentach", ylab="liczba przypadków")
abline(v = 1.5, col = "blue", lty = 2)
tdm <- tdm[, apply(tdm, 2, sum) > 4]
tdm
tdm <- as.matrix(tdm)
ind <- apply(tdm, 1, sum) > 1
tdm <- tdm[ind, ]
class <- data.bbc$emo[ind]
dim(tdm); length(class)
library(MASS)
CM <- function(org.class, pred.class) {
CM <- table(org.class, pred.class)
return(sum(diag(CM)) / sum(CM))
}
bbc.lda <- lda(tdm, class)
bbc.lda.pred <- predict(bbc.lda, tdm)
table(class, bbc.lda.pred$class)
CM(class, bbc.lda.pred$class)
bbc.lda.pred <- predict(bbc.lda, tdm)
table(class, bbc.lda.pred$class)
library(e1071)
bbc.svml <- svm(tdm, class, type = "C-classification", kernel = "linear")
install.packages("e1071")
library(e1071)
bbc.svml <- svm(tdm, class, type = "C-classification", kernel = "linear")
bbc.svml.pred <- predict(bbc.svml, tdm)
table(class, bbc.svml.pred)
CM(class, bbc.svml.pred)
bbc.svmr <- svm(tdm, class, type = "C-classification")
bbc.svmr.pred <- predict(bbc.svmr, tdm)
table(class, bbc.svmr.pred)
CM(class, bbc.svmr.pred)
library(caret)
install.packages("caret")
levels(class) <- c("neg", "pos")
data <- cbind(as.data.frame(tdm), class.out = class)
fit <- trainControl(method = "cv", number = 10)
model <- train(class.out ~ ., data = data, method = "svmLinear", trControl = fit)
library(caret)
levels(class) <- c("neg", "pos")
data <- cbind(as.data.frame(tdm), class.out = class)
fit <- trainControl(method = "cv", number = 10)
model <- train(class.out ~ ., data = data, method = "svmLinear", trControl = fit)
library(caret)
levels(class) <- c("neg", "pos")
data <- cbind(as.data.frame(tdm), class.out = class)
data <- cbind(as.data.frame(tdm), class.out = class)
fit <- trainControl(method = "cv", number = 10)
model <- train(class.out ~ ., data = data, method = "svmLinear", trControl = fit)
model
model.lda <- train(class.out ~ ., data = data, method = "lda", trControl = fit)
res <- resamples(list(LDA = model.lda, SVM = model))
bwplot(res)
confusionMatrix(model)
confusionMatrix(model.lda)
